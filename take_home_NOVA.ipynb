{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPfVc5EtnIk+ex+/DbVMhpJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nickallen0/NOVA_takehome/blob/main/take_home_NOVA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34Li2ia03SYL",
        "outputId": "81db57db-ef25-40ac-cd3f-49f18335cee6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import random\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "my_drive = \"/content/drive/MyDrive\"\n",
        "root_folder = my_drive+'/NOVA_course_deep_learning_full/data/annotated_data/'  # Replace with the path to your root folder\n",
        "main_folder = root_folder+'/full'  # Replace with the path to your main folder\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Assemble all the class data into one unified folder structure and perform the train/val split"
      ],
      "metadata": {
        "id": "8oriOC_ENc-z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the folder structure if it doesn't exist for all the images and annotations\n",
        "if not os.path.exists(main_folder):\n",
        "    os.makedirs(main_folder)\n",
        "\n",
        "if not os.path.exists(main_folder+'/images'):\n",
        "    os.makedirs(main_folder+'/images')\n",
        "images = main_folder+'/images'\n",
        "\n",
        "if not os.path.exists(main_folder+'/labels'):\n",
        "    os.makedirs(main_folder+'/labels')\n",
        "labels = main_folder+'/labels'\n",
        "\n"
      ],
      "metadata": {
        "id": "Xx3FOa-W3juW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find all image files in the subfolders\n",
        "image_files = glob.glob(os.path.join(root_folder, '*', '*', '*.tif'))\n",
        "label_files = glob.glob(os.path.join(root_folder, '*', '*', '*.txt'))\n",
        "\n",
        "# Copy image files to the main folder under images\n",
        "for src in image_files:\n",
        "    dst = os.path.join(images, os.path.basename(src))\n",
        "    shutil.copy(src, dst)\n",
        "\n",
        "# Copy label files into the main folder labels under labels\n",
        "for src in label_files:\n",
        "    dst = os.path.join(labels, os.path.basename(src))\n",
        "    shutil.copy(src, dst)"
      ],
      "metadata": {
        "id": "QcDFbqZx7uCj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split all the data into a train/val\n",
        "path_to_tiles=\"/content/drive/MyDrive/NOVA_course_deep_learning_full/data/annotated_data/full\"\n"
      ],
      "metadata": {
        "id": "1BGZAuVMBE1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define split for training and validation\n",
        "split_train= 0.7\n",
        "split_val=1-split_train"
      ],
      "metadata": {
        "id": "fDKpcCEyN-m7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create train and val directories\n",
        "train_dir = os.path.join(path_to_tiles, \"train\")\n",
        "os.makedirs(train_dir, exist_ok=True) # creates new directory for training data\n",
        "val_dir = os.path.join(path_to_tiles, \"val\")\n",
        "os.makedirs(val_dir, exist_ok=True) # creates new directory for validation data\n",
        "val_img_dir = os.path.join(path_to_tiles, \"val\",\"images\")\n",
        "os.makedirs(val_img_dir, exist_ok=True) # creates new directory for training data\n",
        "train_img_dir = os.path.join(path_to_tiles, \"train\",\"images\")\n",
        "os.makedirs(train_img_dir, exist_ok=True) # creates new directory for training data\n",
        "val_ann_dir = os.path.join(path_to_tiles, \"val\",\"labels\")\n",
        "os.makedirs(val_ann_dir, exist_ok=True) # creates new directory for training data\n",
        "train_ann_dir = os.path.join(path_to_tiles, \"train\",\"labels\")\n",
        "os.makedirs(train_ann_dir, exist_ok=True) # creates new directory for training data"
      ],
      "metadata": {
        "id": "UsNOMm9wB2Vd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a list of all the .txt files in the data directory\n",
        "txt_files = [f for f in os.listdir(labels) if f.endswith(\".txt\")]\n",
        "img_files = [f for f in os.listdir(images) if f.endswith(\".tif\")]"
      ],
      "metadata": {
        "id": "H-wNt6p3CgFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle the list of text files\n",
        "random.shuffle(txt_files)\n",
        "#train=random.sample(txt_files, )\n",
        "\n",
        "# Calculate the number of files for the train and validation sets\n",
        "train_size = int(0.7 * len(txt_files))\n",
        "val_size = len(txt_files) - train_size\n"
      ],
      "metadata": {
        "id": "yP43ZCQACiCM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(txt_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w36ncFZpyrvK",
        "outputId": "1259e8a6-cf97-4895-b0dd-c50b828f9d1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# iterate through each annotated .txt file\n",
        "for i, txt_file in enumerate(txt_files):\n",
        "    if i < train_size:\n",
        "        dest_dir = train_dir\n",
        "    else:\n",
        "        dest_dir = val_dir\n",
        "\n",
        "    src_file = os.path.join(labels, txt_file)\n",
        "    src_img = os.path.join(images, os.path.splitext(txt_file)[0] + \".tif\")\n",
        "\n",
        "    dest_file = os.path.join(dest_dir,\"labels\", txt_file)\n",
        "    dest_img = os.path.join(dest_dir,\"images\", os.path.splitext(txt_file)[0]+\".tif\")\n",
        "\n",
        "    #print(\"copying files\")\n",
        "\n",
        "    shutil.move(src_file, dest_file)\n",
        "    shutil.move(src_img, dest_img)"
      ],
      "metadata": {
        "id": "GMO28_0cDIkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train a model on the full class dataset"
      ],
      "metadata": {
        "id": "H8EyhHNTNVAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install comet_ml --quiet\n",
        "import comet_ml # in future scripts this should be pasted before importing the ultralytics library"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jyo6fjEgOzDK",
        "outputId": "45dde347-f40d-47a1-be58-0b4fe87dd4f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m534.7/534.7 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m206.7/206.7 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m137.9/137.9 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.3/54.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m510.1/510.1 kB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m123.6/123.6 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.27.1, but you have requests 2.31.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "o4YfVrZQP2Jj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train a model\n",
        "%pip install ultralytics\n",
        "import ultralytics\n",
        "ultralytics.checks()\n",
        "import yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ii4A8n2HBKZs",
        "outputId": "06d8c0f3-5c69-4ca8-f04c-399af1d1bd2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.117 ðŸš€ Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 23.3/78.2 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config_data = {\n",
        "    'path': path_to_tiles,\n",
        "    'train': path_to_tiles+'/train/images',\n",
        "    'val': path_to_tiles+'/val/images',\n",
        "    'test':\"/content/drive/MyDrive/NOVA_course_deep_learning_full/data/annotated_data/test/images\", # this is by default\n",
        "    'names': {\n",
        "        0: 'tree'\n",
        "    }\n",
        "}\n",
        "\n",
        "with open(path_to_tiles+'/train_config.yaml', 'w') as file:\n",
        "    yaml.dump(config_data, file)"
      ],
      "metadata": {
        "id": "mssQzTbEN4Q7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_tiles+'/train_config.yaml'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "RUHLqps1OVbr",
        "outputId": "8ef11e7e-d1f3-4a5c-d008-82988e9a58d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/NOVA_course_deep_learning_full/data/annotated_data/full/train_config.yaml'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Train"
      ],
      "metadata": {
        "id": "hEfZShLwOXnD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo train model=yolov8n.pt data=$path_to_tiles'/train_config.yaml' epochs=300 imgsz=640 project=$path_to_tiles name=\"seedlingsFull_YOLOn_img640\""
      ],
      "metadata": {
        "id": "2bs3FXGXOVTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo train model=yolov8m.pt data=$path_to_tiles'/train_config.yaml' epochs=300 imgsz=640 project=$path_to_tiles name=\"seedlingsFull_YOLOm_img640\""
      ],
      "metadata": {
        "id": "XNPInnWYTpAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo train model=yolov8n.pt data=$path_to_tiles'/train_config.yaml' epochs=300 imgsz=1024 project=$path_to_tiles name=\"seedlingsFull_YOLOn_img1024\""
      ],
      "metadata": {
        "id": "a_i7V6XKTvIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo train model=yolov8m.pt data=$path_to_tiles'/train_config.yaml' epochs=300 imgsz=1024 project=$path_to_tiles name=\"seedlingsFull_YOLOm_img1024\""
      ],
      "metadata": {
        "id": "5KnITORfT0xj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Inference\n"
      ],
      "metadata": {
        "id": "FC4_i-7Sy_3q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hk5JIs6sy45s"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "annotator_ID=1 # change this to your folder ID\n",
        "\n",
        "path_to_ortho_predict= \"/content/drive/MyDrive/NOVA_course_deep_learning_full/data/orthomosaics/test_data/braatan_40m20230605_sun.tif\" #now four of these not 1, will need to specify one by one\n",
        "path_to_ortho_predict2= \"/content/drive/MyDrive/NOVA_course_deep_learning_full/data/orthomosaics/test_data/galbyveien_20230504_sun.tif\"\n",
        "path_to_ortho_predict3= \"/content/drive/MyDrive/NOVA_course_deep_learning_full/data/orthomosaics/test_data/krakstad_202304_sun.tif\"\n",
        "path_to_ortho_predict4= \"/content/drive/MyDrive/NOVA_course_deep_learning_full/data/orthomosaics/test_data/ortho_hobol_042222_mavic_sun\"\n",
        "\n",
        "path_to_tiles_G=\"/content/drive/MyDrive/NOVA_course_deep_learning_full/data/tiles/10m_galbyveien_20230504_sun\"\n",
        "path_to_tiles_K=\"/content/drive/MyDrive/NOVA_course_deep_learning_full/data/tiles/10m_krakstad_202304_sun\"\n",
        "path_to_model=\"/content/drive/MyDrive/NOVA_course_deep_learning_full/data/annotated_data/full/seedlingsFull_YOLOn_img640/weights/best.pt\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# other libraries\n",
        "!pip install geopandas\n",
        "!pip install rasterio\n",
        "!pip install folium matplotlib mapclassify\n",
        "# general python packages\n",
        "import os, glob, shutil\n",
        "from pathlib import Path\n",
        "from datetime import datetime, timedelta\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import folium\n",
        "#import warnings\n",
        "#warnings.filterwarnings(\"ignore\")\n",
        "#import sys\n",
        "\n",
        "# geospatial packages\n",
        "from osgeo import gdal, ogr, osr\n",
        "import geopandas as gpd\n",
        "from shapely.geometry import Polygon\n",
        "import rasterio as rio\n",
        "path_osgeo_utils= \"/usr/local/lib/python3.10/dist-packages/osgeo_utils\" # defines path to gdal_retile.py"
      ],
      "metadata": {
        "id": "lZVIZDwL0R9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "npc7eMvI0Uki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Params:\n",
        "#   - input_ortho_path: path to orthophoto to predict on (\"/content/drive/MyDrive/NOVA_course_deep_learning/data/orthomosaics/test_data/krakstad_202304_sun.tif\")\n",
        "#   - footprints_path: path to multipolygon layer of tile footprints (\"/content/drive/MyDrive/NOVA_course_deep_learning/data/map_data/drone_acquisitions.geojson\")\n",
        "#   - tile_size_m: tile size in m\n",
        "#   - buffer_size_m= size of overlap area around each tile in m (used for removing boundary effects)\n",
        "# input_ortho_path=\n",
        "# footprints_path=\n",
        "\n",
        "def tile_orthomosaic(input_ortho_path,footprints_path, tile_size_m, buffer_size_m):\n",
        "  # Define path to data\n",
        "  path_data=\"/content/drive/MyDrive/NOVA_course_deep_learning_full/data\"\n",
        "\n",
        "  # read drone acquisition footprints\n",
        "  footprints= gpd.read_file(footprints_path)\n",
        "  # Get ortho name\n",
        "  ortho_name=os.path.splitext(os.path.basename(input_ortho_path)) [0]\n",
        "\n",
        "  # create output dir\n",
        "  output_tiles_dir=path_data+\"/tiles/\"+str(tile_size_m)+\"m_\"+ortho_name\n",
        "  if not os.path.exists(output_tiles_dir):\n",
        "    print(\"Creating output folder...\"+ output_tiles_dir)\n",
        "    os.makedirs(output_tiles_dir)\n",
        "\n",
        "  # get raster metadata\n",
        "  # Get pixel resolution (in meters) and tile size in pixels\n",
        "  src_ds = gdal.Open(input_ortho_path) # reads in the orthomosaic\n",
        "  _, xres, _, _, _, yres  = src_ds.GetGeoTransform() # get pixel size in meters\n",
        "  print(\"Ortho resolution: \"+str(round(xres,4))+\" m\")\n",
        "  # Get EPSG code\n",
        "  proj = osr.SpatialReference(wkt=src_ds.GetProjection())\n",
        "  EPSG_code= proj.GetAttrValue('AUTHORITY',1)\n",
        "  print(\"EPSG code: \"+str(EPSG_code))\n",
        "  # get number of bands\n",
        "  n_bands=src_ds.RasterCount\n",
        "  print(\"Number of bands: \"+str(n_bands))\n",
        "\n",
        "  # Compute tile and buffer size in pixels\n",
        "  tile_size_px= round(tile_size_m/abs(xres)) # calculate the tile size in pixels\n",
        "  buffer_size_px= round(buffer_size_m/abs(xres)) # calculate the buffer size in pixels\n",
        "  tileIndex_name=ortho_name+\"_tile_index\" # define name for output tile index shapefile\n",
        "\n",
        "  # Run gdal_retile.py using (can take some minutes)\n",
        "  command_retile = \"python \"+path_osgeo_utils+\"/gdal_retile.py -targetDir \" + output_tiles_dir + \" \" + input_ortho_path+ \" -overlap \" + str(buffer_size_px) + \" -ps \"+str(tile_size_px) + \" \" + str(tile_size_px) + \" -of GTiff -tileIndex \"+ tileIndex_name + \" -tileIndexField ID\"\n",
        "  print(os.popen(command_retile).read()) ################################################################### SWITCH THIS ONE FOR TILING #########################################\n",
        "\n",
        "  # cleanup tiles\n",
        "  footprint_ortho= footprints[footprints['filename']==ortho_name]\n",
        "  footprint_ortho_UU= footprint_ortho.geometry.unary_union\n",
        "  # Load tiles shapefile\n",
        "  tiles = gpd.read_file(output_tiles_dir+ \"/\"+ortho_name+\"_tile_index.shp\")\n",
        "  tiles= tiles.to_crs(EPSG_code)\n",
        "\n",
        "  # Select all tiles that are within the boundary polygon\n",
        "  tiles_in = tiles[tiles.geometry.within(footprint_ortho_UU)]\n",
        "\n",
        "  # Select all tiles that are not within the boundary polygon\n",
        "  tiles_out= tiles.loc[~tiles['ID'].isin(tiles_in['ID']) ]\n",
        "  print(str(len(tiles_out))+\" tiles to be deleted\")\n",
        "\n",
        "  # delete tiles that are not within the footprint\n",
        "  gtiffs_delete=[output_tiles_dir+ \"/\"+sub  for sub in tiles_out['ID']]\n",
        "  for f in gtiffs_delete:\n",
        "   if os.path.exists(f):\n",
        "     os.remove(f)\n",
        "\n"
      ],
      "metadata": {
        "id": "qp1yYAXi0adI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tile_orthomosaic(input_ortho_path=path_to_ortho_predict2, #need to iterate for the four areas in the folder\n",
        "                 footprints_path= \"/content/drive/MyDrive/NOVA_course_deep_learning_full/data/map_data/drone_acquisitions.geojson\",\n",
        "                 tile_size_m=10, # this could be changed\n",
        "                 buffer_size_m=1) # this could be changed"
      ],
      "metadata": {
        "id": "22YmFdTi0baH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tile_orthomosaic(input_ortho_path=path_to_ortho_predict3, #need to iterate for the four areas in the folder\n",
        "                 footprints_path= \"/content/drive/MyDrive/NOVA_course_deep_learning_full/data/map_data/drone_acquisitions.geojson\",\n",
        "                 tile_size_m=10, # this could be changed\n",
        "                 buffer_size_m=1) # this could be changed"
      ],
      "metadata": {
        "id": "MBc-aiqQ6F-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_model = \"/content/drive/MyDrive/NOVA_course_deep_learning/data/annotated_data/train/1/seedlingsHobol_YOLOm_img640/weights/best.pt\"\n",
        "full_model = path_to_model"
      ],
      "metadata": {
        "id": "MYmClbkMGzAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_model"
      ],
      "metadata": {
        "id": "203GI-SaG99K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Inference"
      ],
      "metadata": {
        "id": "9Z1rFlowgxo8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Use the model to find trees in the data"
      ],
      "metadata": {
        "id": "FiC4oSK0hXUG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install ultralytics\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ],
      "metadata": {
        "id": "q6ozXtR5IQVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo predict model=$my_model source=$path_to_tiles_K imgsz=640 conf=0.4 project=$path_to_tiles_K name=predict_tiles_mine save_txt=True save_conf=True save=True line_width=1"
      ],
      "metadata": {
        "id": "R2TpLy2iHeAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo predict model=$path_to_model source=$path_to_tiles_K imgsz=640 conf=0.4 project=$path_to_tiles_K name=predict_tiles_full save_txt=True save_conf=True save=True line_width=1"
      ],
      "metadata": {
        "id": "sBOI_syUC1FR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Postprocessing"
      ],
      "metadata": {
        "id": "9O6qExyYw1Ky"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Go from YOLO bounding boxes to domain metrics to compare the results"
      ],
      "metadata": {
        "id": "en7Pq17RhutC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://colab.research.google.com/drive/1LJh6ymvCOJbQoHOz1j61sMBTSf72BZaq?usp=sharing"
      ],
      "metadata": {
        "id": "i6dq4RzEwxT5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R2m2f4Ath2sN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}